<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ComSL - Composite Speech Language Model | Atishay Jain</title> <meta name="author" content="Atishay Jain"> <meta name="description" content="an example of a blog post with some math"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/letter-a.png?e633e8fed3817b73400ccd2c03d6f771"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://atishay25.github.io/blog/2024/comsl/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Atishay Jain</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/hobbies/">Hobbies</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">ComSL - Composite Speech Language Model</h1> <p class="post-meta">April 17, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/language"> <i class="fa-solid fa-hashtag fa-sm"></i> Language</a>   <a href="/blog/tag/speech"> <i class="fa-solid fa-hashtag fa-sm"></i> Speech</a>   <a href="/blog/tag/translation"> <i class="fa-solid fa-hashtag fa-sm"></i> Translation</a>     ·   <a href="/blog/category/asr"> <i class="fa-solid fa-tag fa-sm"></i> ASR</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><em>NOTE: This Blog is part of ASR course</em></p> <p>Are you tired of your speech-to-text translations sounding like they’ve been through a game of telephone with a mischievous gremlin? Fear not, because ComSL is here to save the day! Picture this: a speech-language model so revolutionary that it’s like blending the perfect smoothie of pre-trained speech and language models, sprinkled with a touch of cross-modality learning magic. Forget the days of awkward mistranslations and GPU overload nightmares - ComSL is about to rock your linguistic world like never before! With a wink to data efficiency and a nod to multi-task learning, ComSL is the superhero we never knew we needed in the realm of end-to-end speech-to-text translation. So grab your popcorn and get ready for a wild ride through the wacky world of speech and language, because ComSL is about to take you on an adventure you won’t soon forget!</p> <h3 id="end-to-end-speechmodels">End to End Speech Models</h3> <p>E2E modeling enables training a single model through E2E optimization with task-oriented metrics. This approach has been widely applied to spoken language tasks in recent years like speech translation, speech summarization, speech understanding etc. A conventional E2E model pipeline design generally consists of 2 modules :</p> <ol> <li>Speech Model : decodes input speech into text</li> <li>Language Model : infers recognized text to target language (translation task), topic sentence (summarization task) or intent (understanding task)</li> </ol> <p>Point to be noted is that these 2 modules are trained using their own respective criteria, which may not be optimal for each other. Therefore, the cascases process may propagate errors that might have occured in a current module to the one following it. Also, since other information like prosodic features are contained in the speech, it becomes difficult to quantize them using language symbols, however they can be beneficial for spoken language tasks.</p> <p>Therefore, unified speech language pretraining based on Transformer architecture has came into play and has largely boosted E2E modeling for spoken language tasks. In such models, pretraining is conducted jointly on unlabeled speech, unlabeled text, paired speech-to-text and paired text-to-text in multiple languages using both supervised and self-supervised learning. The unified representation from both modalities are simultaneously learned via shared model parameters or auxiliary modality matching losses in pretraining stage. But, as pretrained speech-only and language-only models are becoming increasing powerful, to achieve a comparable performance with such a cascaded module system, unified speech-language pretraining must leverage same or larger scale of data used in only models, which makes training very challenging.</p> <h3 id="aim-of-this-paper">Aim of this Paper</h3> <p>ComSL: a Composite Speech-Language Model for spoken language tasks, which -</p> <ul> <li>fully leverages existing pretrained models, therefore, no need for pretraining with large data from scratch, you can just directly fine-tune it for downstream tasks. Hence, it is data efficient</li> <li>Conventional approaches use contrastive learning among modalities, which require external or internal aligners to force-align speech &amp; text at token/word level. But ComSL’s cross-modality learning with speech-text mapping/matching on either representations is only based on concatenation of paired speech &amp; text. This simplifies implementation and allows it to be incorporated in fine-tuning stage</li> <li>Includes comprehensive ablation study on bridging gap of speech &amp; languages and comparisons with previous works</li> <li>The model outperforms SOTA Google USM, OpenAI whisper ad cascaded non-E2E models by 0.8, 1.8, 1.0 average BLEU score improvements on CoVoST2 evaluation set respectively</li> </ul> <h2 id="method">Method</h2> <h3 id="problem-formulation">Problem Formulation</h3> <p>As we have seen now, the goal of E2E speech translation is to directly translate speech from a source language (\(L_1\)) into text in a target language (\(L_2\)), without generating an intermediate ASR transcription. Formally, we have to find the most likely sequence \(y = {y_1, y_2, \ldots , y_N}\) (eg. words or characters) of length \(N\) in \(L_2\) given acoustic features \(s = {s_1, s_2, \ldots , s_T}\) (eg. Mel Filter Bank features) of length \(T\) in \(L_1\). A Speech Translation (ST) corpus \(D^{ST} = \{(s, x, y)\}\)</p> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Atishay Jain. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: April 18, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>